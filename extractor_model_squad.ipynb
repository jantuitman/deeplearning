{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bmJMRGgtnpNf-HMUOVXJ9kuZSzqKzLBr",
      "authorship_tag": "ABX9TyNQwG6jzkdw9uu0Ot4Ns9yU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jantuitman/deeplearning/blob/main/extractor_model_squad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maak vragen van teksten.\n",
        "\n",
        "Dit notebook gebruikt GPT-3 om vragen van teksten te maken.\n"
      ],
      "metadata": {
        "id": "qOMTTcbmblkz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZs-k2Lgbctw",
        "outputId": "e5554ec5-3fc9-43c4-9a35-a2bb04ea6812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=2b396e6269f2802e479fbbc0c3327ab3397d3a56d303f3e57c30698a9715c104\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install pandas\n",
        "!pip install pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wat algemene imports\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import openai\n"
      ],
      "metadata": {
        "id": "egUwvv86jBxW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Squad v2 dataset\n",
        "\n",
        "Dit is een functie die de squad v2 dataset (in een afwijkend formaat met nederlandse vertalingen er in) inleest in een array.Verderop gaan we die teksten verder opsplitsen in zinnen en paragrafen maar dat koppelen we niet hard aan Squad, zodat we het ook op de werkteksten kunnen toepassen.\n"
      ],
      "metadata": {
        "id": "dmnBYD3-gxTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read a json file containing an array of objects\n",
        "# each object has a \"question\" and \"answer\" field\n",
        "# the question is the input and the answer is the output\n",
        "# we will return a list of tuples\n",
        "def read_squadv2_dataset(filename):\n",
        "    with open(filename) as f:\n",
        "        data = json.load(f)\n",
        "        # data has the following structure:\n",
        "        # data = {\n",
        "        #     \"paragraphs\": [\n",
        "        #         {\n",
        "        #             \"translated_context\": \"text\",\n",
        "        #             \"translated_question\": \"text\",\n",
        "        #             \"translated_answers\": [\n",
        "        #                 \"text\",\n",
        "        #                 \"text\",\n",
        "        #                 \"text\"\n",
        "        #             ],\n",
        "        #             \"is_impossible\": true\n",
        "        #         },\n",
        "        #         ...\n",
        "        #     ]\n",
        "        # }\n",
        "        # if is_impossible is true, then translated_answers is empty and we want to return the answer \"Onbekend\"\n",
        "        # if is_impossible is false, then translated_answers is not empty and we want to return the first answer\n",
        "        # we will return a list of tuples\n",
        "        # we need to make a question_text from the translated_context and translated_question\n",
        "        result= []\n",
        "        previous_found_context = None\n",
        "        for paragraph in data['paragraphs']:\n",
        "          if paragraph['translated_context'] != previous_found_context:\n",
        "            if previous_found_context is not None:\n",
        "              result.append(previous_found_context)\n",
        "            previous_found_context = paragraph['translated_context']    \n",
        "        if previous_found_context is not None:\n",
        "          result.append(previous_found_context)\n",
        "        return result"
      ],
      "metadata": {
        "id": "D9BooWIae19u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De stap hier beneden leest de eerste 10% van de squad v2 dataset van Jan uit Jans Google drive. TODO: verhuis deze dataset naar een locatie in dit-werkt.nl waar Google colab makkelijk bij kan.\n",
        "\n",
        "Als handmatige stap benodigd totdat dat gedaan is: zorg dat je een google drive hebt en plaats een file die dev-nl.json heet in een map InputFiles in google drive.\n",
        "\n",
        "In de linkerbalk op google colabs kun je je drive koppelen.\n"
      ],
      "metadata": {
        "id": "SywzMU3ee6pI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "squad_texts = read_squadv2_dataset('drive/MyDrive/InputData/dev-nl.json')\n",
        "\n",
        "# controle resultaten door het weer te geven als een pandas dataframe\n",
        "\n",
        "pd.DataFrame(squad_texts,columns=[\"squad_paragraph\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "65tv2IUNiC9V",
        "outputId": "c2281269-9fca-4986-f2dc-9f151ac62d60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        squad_paragraph\n",
              "0     De Normandiërs (Norman: Nourmands; Frans: Norm...\n",
              "1     De Normandische dynastie had een grote politie...\n",
              "2     De Engelse naam \"Normans\" komt van de Franse w...\n",
              "3     In de loop van de 10e eeuw veranderden de aanv...\n",
              "4     Voor de komst van Rollo verschilde de bevolkin...\n",
              "...                                                 ...\n",
              "2912  waarin de massa van het voorwerp is, de snelhe...\n",
              "2913  Een conservatieve kracht die inwerkt op een ge...\n",
              "2914  Voor bepaalde fysische scenario's is het onmog...\n",
              "2915  Het verband tussen macroscopische niet-conserv...\n",
              "2916  De pondkracht heeft een metrische tegenhanger,...\n",
              "\n",
              "[2917 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb414a7e-b28b-458e-88fc-74a1776bb90e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>squad_paragraph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>De Normandiërs (Norman: Nourmands; Frans: Norm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>De Normandische dynastie had een grote politie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>De Engelse naam \"Normans\" komt van de Franse w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In de loop van de 10e eeuw veranderden de aanv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Voor de komst van Rollo verschilde de bevolkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>waarin de massa van het voorwerp is, de snelhe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>Een conservatieve kracht die inwerkt op een ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2914</th>\n",
              "      <td>Voor bepaalde fysische scenario's is het onmog...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2915</th>\n",
              "      <td>Het verband tussen macroscopische niet-conserv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2916</th>\n",
              "      <td>De pondkracht heeft een metrische tegenhanger,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2917 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb414a7e-b28b-458e-88fc-74a1776bb90e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb414a7e-b28b-458e-88fc-74a1776bb90e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb414a7e-b28b-458e-88fc-74a1776bb90e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functie om arrays van tekst te converteren naar tuples van zinnen en paragrafen.\n",
        "\n",
        "Een tekst kan meerdere paragrafen bevatten gescheiden door newlines (\\n tekens). Een paragraaf kan meerdere zinnen bevatten, gescheiden door punten, uitroeptekens en vraagtekens.\n",
        "\n",
        "Het resultaat van de functie moet een lijst van tuples zijn.\n",
        "\n",
        "Deze functie is een \"poor mans parser\" want hij kan niet overweg met ingewikkelde dingen zoals quotes in quotes, meerdere paragrafen binnen een quote, mensen die vergeten quotes af te sluiten, enz. enz.\n",
        "In de toekomst kan de parser misschien vervangen worden door een AI model die parst. Maar voor nu is het niet zo belangrijk omdat we zelf wel controle hebben over de data die we er mee parsen.\n",
        "\n",
        "```\n",
        "[\n",
        "  ('sentence','De eerste zin van de tekst.'),\n",
        "  ('sentence','De tweede zin van de tekst.'),\n",
        "  ('paragraph','De eerste paragraaf, die komt na alle zinnen van de eerste paragraaf.'),\n",
        "  ('sentence','De derde zin van de tekst, die in de tweede paragraaf zit.'),\n",
        "  ('sentence','De vierde zin van de tekst, die in de tweede paragraaf zit.'),\n",
        "  ('paragraph','De tweede paragraaf, die komt na alle zinnen van de tweede paragraaf.'),\n",
        "  ...\n",
        "]\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Dd5gBivvje5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def split_text(text):\n",
        "    result = []\n",
        "    paragraphs = text.split('\\n')\n",
        "    for i, paragraph in enumerate(paragraphs):\n",
        "        sentence = \"\"\n",
        "        in_quote = False\n",
        "        for c in paragraph:\n",
        "            if c == '\"' or c == \"'\":\n",
        "                in_quote = not in_quote\n",
        "            if c in \".!?\":\n",
        "                if not in_quote:\n",
        "                    if sentence != \"\":\n",
        "                        sentence += c\n",
        "                        result.append(('sentence', sentence.strip(),paragraph))\n",
        "                        sentence = \"\"\n",
        "            else:\n",
        "                sentence += c\n",
        "        if sentence != \"\":\n",
        "            result.append(('sentence', sentence.strip(),paragraph))\n",
        "        result.append(('paragraph',paragraph, None))    \n",
        "    return result"
      ],
      "metadata": {
        "id": "FrCxAYRgkl7w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# de test of het werkt.\n",
        "split_text(\"'Geloof je dat echt? Ik ben het er niet mee eens', zei hij. Daarna ging hij naar de winkel.\\nDit is een tekst met meerdere punten... En nog een zinnetje!\\nGaat alles goed?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptCVIWN5vCRL",
        "outputId": "1062ff05-cc10-43b0-9e79-28c48d4776d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sentence',\n",
              "  \"'Geloof je dat echt Ik ben het er niet mee eens', zei hij.\",\n",
              "  \"'Geloof je dat echt? Ik ben het er niet mee eens', zei hij. Daarna ging hij naar de winkel.\"),\n",
              " ('sentence',\n",
              "  'Daarna ging hij naar de winkel.',\n",
              "  \"'Geloof je dat echt? Ik ben het er niet mee eens', zei hij. Daarna ging hij naar de winkel.\"),\n",
              " ('paragraph',\n",
              "  \"'Geloof je dat echt? Ik ben het er niet mee eens', zei hij. Daarna ging hij naar de winkel.\",\n",
              "  None),\n",
              " ('sentence',\n",
              "  'Dit is een tekst met meerdere punten.',\n",
              "  'Dit is een tekst met meerdere punten... En nog een zinnetje!'),\n",
              " ('sentence',\n",
              "  'En nog een zinnetje!',\n",
              "  'Dit is een tekst met meerdere punten... En nog een zinnetje!'),\n",
              " ('paragraph',\n",
              "  'Dit is een tekst met meerdere punten... En nog een zinnetje!',\n",
              "  None),\n",
              " ('sentence', 'Gaat alles goed?', 'Gaat alles goed?'),\n",
              " ('paragraph', 'Gaat alles goed?', None)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT 3 prompts voor het verwerken van de sentences en paragrafen\n",
        "\n",
        "Deze prompt gebruiken we om aan GPT3 te vertellen hoe we een zin willen omvormen naar vragen over de zin. We hebben een aparte prompt voor paragrafen."
      ],
      "metadata": {
        "id": "b6l0BZqhzIIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "data_set = [split_text(text) for text in squad_texts]\n",
        "data_set = list(itertools.chain.from_iterable(data_set))\n",
        "None"
      ],
      "metadata": {
        "id": "WVuTm9UA8xHR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT functie om 1 tuple te verwerken."
      ],
      "metadata": {
        "id": "eGiCQ3z09msK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def genereer_vragen(text):\n",
        "  prompt = f\"\"\"\n",
        "  \n",
        "      INSTRUCTIE: Verzin 5 vragen waarvan het antwoord in onderstaande tekst gegeven is.\n",
        "      TEKST: Een van de eerste Normandische huurlingen die als Byzantijnse generaal diende was Hervé in de jaren 1050. Tegen die tijd dienden er echter al Normandische huurlingen tot in Trebizond en Georgië. Zij waren gelegerd in Malatya en Edessa, onder de Byzantijnse hertog van Antiochië, Isaac Komnenos.  \n",
        "\n",
        "      VRAGEN:\n",
        "      1. Wie was een van de eerste Normandische huurlingen die als Byzantijnse generaal diende?\n",
        "      2. In welke jaren diende Hervé als Byzantijnze generaal.\n",
        "      3. In welke streken of landen dienden ook al Normandische huurlingen toen Hervé als Byzantijnse generaal diende?\n",
        "      4. In welke steden waren Normandische huurlingen gelegerd die dienden onder Isaac Komnenos?\n",
        "      5. Hoe heette de Byzantijnze hertog van Antiochië?\n",
        "\n",
        "\n",
        "      INSTRUCTIE: Verzin 5 vragen waarvan het antwoord in onderstaande tekst gegeven is.\n",
        "      TEKST: Een medewerker tuincentrum verkoopt artikelen in een tuincentrum, zoals bloemen, planten en tuinartikelen. Voorbeelden van werkzaamheden van de medewerker tuincentrum: helpt klanten, adviseert over producten, verzorgt bloemen en planten, maakt eenvoudige boeketten en bindt ze, laat goederen aan de kassa afrekenen, etaleert, houdt verkoopruimtes schoon en behandelt klachten.\n",
        " \n",
        "      VRAGEN:\n",
        "      1. Wat is een medewerker tuincentrum?\n",
        "      2. Wat verkoopt een medewerker tuincentrum?\n",
        "      3. Wat zijn voorbeelden van werkzaamheden van een medewerker tuincentrum?\n",
        "      4. Wat verzorgt een medewerker tuincentrum?\n",
        "      5. Moet een mederwerker tuincentrum ook klachten behandelen? \n",
        "\n",
        "      INSTRUCTIE: Verzin 5 vragen waarvan het antwoord in onderstaande tekst gegeven is.\n",
        "      TEKST:{text}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  completions = openai.Completion.create(\n",
        "        engine=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        stop=[\"TEKST\",\"INSTRUCTIE\"],\n",
        "        temperature=0.7,\n",
        "        api_key=api_key\n",
        "  )\n",
        "  generated_text = completions.choices[0].text\n",
        "  lines = generated_text.split(\"\\n\")\n",
        "\n",
        "  is_question = lambda text: bool(re.match(r'^\\s*\\d+[.][ ].*\\?\\s*$', text))\n",
        "  extract_question = lambda text: re.sub(r'^\\s*\\d+[.]\\s*', '', text).strip()\n",
        "  questions = list(filter(is_question, lines))\n",
        "  questions_texts = [extract_question(question) for question in questions]\n",
        "\n",
        "  return questions_texts"
      ],
      "metadata": {
        "id": "PLwXjtOHWOm0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_secrets():\n",
        "    with open(\"drive/MyDrive/InputData/secrets.yml\", 'r') as file:\n",
        "        data = yaml.safe_load(file)\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "CeogtJv78gtz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "secrets = read_secrets()\n",
        "api_key = secrets['open-api']['key']\n",
        "model = 'text-davinci-003'"
      ],
      "metadata": {
        "id": "7ufxNwPOU4WX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for item in data_set[:20]:\n",
        "  text_type, text,x = item\n",
        "  if text_type == \"paragraph\":\n",
        "    questions=genereer_vragen(text)\n",
        "    results.append({ 'context': text, 'questions': questions})\n",
        "\n",
        "print(json.dumps(results,indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0bd7kW_Vucl",
        "outputId": "b0f81471-4b8c-4f43-8a11-7ab97f79e9b6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"context\": \"De Normandi\\u00ebrs (Norman: Nourmands; Frans: Normands; Latijn: Normanni) waren de mensen die in de 10e en 11e eeuw hun naam gaven aan Normandi\\u00eb, een regio in Frankrijk. Zij stamden af van Noorse (\\\"Norman\\\" komt van \\\"Noorman\\\") rovers en piraten uit Denemarken, IJsland en Noorwegen die onder hun leider Rollo trouw zwoeren aan koning Karel III van West-Frankrijk. Door generaties van assimilatie en vermenging met de inheemse Frankische en Romeins-Gaulische bevolking, zouden hun afstammelingen geleidelijk samensmelten met de op Karolingische leest geschoeide culturen van West-Frankrijk. De aparte culturele en etnische identiteit van de Noormannen ontstond aanvankelijk in de eerste helft van de 10e eeuw en bleef zich in de daaropvolgende eeuwen ontwikkelen.\",\n",
            "        \"questions\": [\n",
            "            \"Vanwaar komt de naam Normandi\\u00eb?\",\n",
            "            \"Uit welke landen stamden de Normandi\\u00ebrs af?\",\n",
            "            \"Wie was de leider van de Normandi\\u00ebrs?\",\n",
            "            \"Wat gebeurde er door generaties van assimilatie en vermenging met de inheemse bevolking?\",\n",
            "            \"Wanneer ontstond de aparte culturele en etnische identiteit van de Noormannen?\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"De Normandische dynastie had een grote politieke, culturele en militaire invloed op het middeleeuwse Europa en zelfs op het Nabije Oosten. De Noormannen werden beroemd om hun krijgshaftigheid en uiteindelijk om hun christelijke vroomheid, en werden exponenten van de katholieke orthodoxie waarin zij zich integreerden. Zij namen de Gallo-Romaanse taal over van het Frankische land waar zij zich vestigden, en hun dialect werd bekend als Normandisch, Normaund of Normandisch Frans, een belangrijke literaire taal. Het hertogdom Normandi\\u00eb, dat zij bij verdrag met de Franse kroon vormden, was een groot leengoed van het middeleeuwse Frankrijk, en werd onder Richard I van Normandi\\u00eb tot een samenhangend en geducht vorstendom in feodale dienst gesmeed. De Normandi\\u00ebrs staan bekend om hun cultuur, zoals hun unieke Romaanse architectuur en muzikale tradities, en om hun belangrijke militaire prestaties en innovaties. Normandische avonturiers stichtten het koninkrijk Sicili\\u00eb onder Roger II, nadat zij Zuid-Itali\\u00eb hadden veroverd op de Saracenen en de Byzantijnen, en een expeditie namens hun hertog, Willem de Veroveraar, leidde tot de Normandische verovering van Engeland in de Slag bij Hastings in 1066. Vanuit deze nieuwe Europese centra verspreidde de Normandische culturele en militaire invloed zich naar de kruisvaardersstaten in het Nabije Oosten, waar hun prins Bohemond I het vorstendom Antiochi\\u00eb in de Levant stichtte, naar Schotland en Wales in Groot-Brittanni\\u00eb, naar Ierland, en naar de kusten van Noord-Afrika en de Canarische Eilanden.\",\n",
            "        \"questions\": [\n",
            "            \"Wat was de grote politieke, culturele en militaire invloed van de Normandische dynastie?\",\n",
            "            \"Wat stonden de Noormannen vooral bekend om?\",\n",
            "            \"Wat voor taal namen de Normandieren over van het Frankische land waar zij zich vestigden?\",\n",
            "            \"Hoe heette de geduchte hertog van Normandi\\u00eb?\",\n",
            "            \"Wat was de resultaat van de Normandische expeditie onder leiding van Willem de Veroveraar?\"\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"De Engelse naam \\\"Normans\\\" komt van de Franse woorden Normans/Normanz, meervoud van Normant, modern Frans normand, dat op zijn beurt ontleend is aan het Oudnederfrankische Nortmann \\\"Noordman\\\" of rechtstreeks aan het Oudnoorse Nor\\u00f0ma\\u00f0r, gelatiniseerd als Nortmannus, Normannus, of Nordmannus (vastgelegd in middeleeuws Latijn, 9e eeuw) om \\\"Noorman, Viking\\\" te betekenen.\",\n",
            "        \"questions\": [\n",
            "            \"Wat is de Engelse naam voor de Normandi\\u00ebrs?\",\n",
            "            \"Welke Franse woorden komen samen tot de Engelse naam voor de Normandi\\u00ebrs?\",\n",
            "            \"Waar komt het Oudnederfrankische woord Nortmann vandaan?\",\n",
            "            \"Wat betekent het Oudnoorse woord Nor\\u00f0ma\\u00f0r?\",\n",
            "            \"Wat is het Latijnse woord voor Noorman?\"\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('drive/MyDrive/OutputModels/questions2.json', 'r') as file:\n",
        "    array = json.load(file)\n",
        "\n",
        "\n",
        "results = array\n",
        "for count,item in enumerate(data_set):\n",
        "  text_type, text,x = item\n",
        "  if count < 4600:\n",
        "    continue\n",
        "  if text_type == \"paragraph\":\n",
        "    questions=genereer_vragen(text)\n",
        "    results.append({ 'context': text, 'questions': questions})\n",
        "  if count == 5 or (count % 50 == 0):\n",
        "    print(\"saving\",count)\n",
        "    with open('drive/MyDrive/OutputModels/questions.json', 'w') as file:\n",
        "      json.dump(results,file,indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HryA79puaZh5",
        "outputId": "4d6f536a-e247-41eb-a5f9-e32b0c2639d8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving 4600\n",
            "saving 4650\n",
            "saving 4700\n",
            "saving 4750\n",
            "saving 4800\n",
            "saving 4850\n",
            "saving 4900\n",
            "saving 4950\n",
            "saving 5000\n",
            "saving 5050\n",
            "saving 5100\n",
            "saving 5150\n",
            "saving 5200\n",
            "saving 5250\n",
            "saving 5300\n",
            "saving 5350\n",
            "saving 5400\n",
            "saving 5450\n",
            "saving 5500\n",
            "saving 5550\n",
            "saving 5600\n",
            "saving 5650\n",
            "saving 5700\n",
            "saving 5750\n",
            "saving 5800\n",
            "saving 5850\n",
            "saving 5900\n",
            "saving 5950\n",
            "saving 6000\n",
            "saving 6050\n",
            "saving 6100\n",
            "saving 6150\n",
            "saving 6200\n",
            "saving 6250\n",
            "saving 6300\n",
            "saving 6350\n",
            "saving 6400\n",
            "saving 6450\n",
            "saving 6500\n",
            "saving 6550\n",
            "saving 6600\n",
            "saving 6650\n",
            "saving 6700\n",
            "saving 6750\n",
            "saving 6800\n",
            "saving 6850\n",
            "saving 6900\n",
            "saving 6950\n",
            "saving 7000\n",
            "saving 7050\n",
            "saving 7100\n",
            "saving 7150\n",
            "saving 7200\n",
            "saving 7250\n",
            "saving 7300\n",
            "saving 7350\n",
            "saving 7400\n",
            "saving 7450\n",
            "saving 7500\n",
            "saving 7550\n",
            "saving 7600\n",
            "saving 7650\n",
            "saving 7700\n",
            "saving 7750\n",
            "saving 7800\n",
            "saving 7850\n",
            "saving 7900\n",
            "saving 7950\n",
            "saving 8000\n",
            "saving 8050\n",
            "saving 8100\n",
            "saving 8150\n",
            "saving 8200\n",
            "saving 8250\n",
            "saving 8300\n",
            "saving 8350\n",
            "saving 8400\n",
            "saving 8450\n",
            "saving 8500\n",
            "saving 8550\n",
            "saving 8600\n",
            "saving 8650\n",
            "saving 8700\n",
            "saving 8750\n",
            "saving 8800\n",
            "saving 8850\n",
            "saving 8900\n",
            "saving 8950\n",
            "saving 9000\n",
            "saving 9050\n",
            "saving 9100\n",
            "saving 9150\n",
            "saving 9200\n",
            "saving 9250\n",
            "saving 9300\n",
            "saving 9350\n",
            "saving 9400\n",
            "saving 9450\n",
            "saving 9500\n",
            "saving 9550\n",
            "saving 9600\n",
            "saving 9650\n",
            "saving 9700\n",
            "saving 9750\n",
            "saving 9800\n",
            "saving 9850\n",
            "saving 9900\n",
            "saving 9950\n",
            "saving 10000\n",
            "saving 10050\n",
            "saving 10100\n",
            "saving 10150\n",
            "saving 10200\n",
            "saving 10250\n",
            "saving 10300\n",
            "saving 10350\n",
            "saving 10400\n",
            "saving 10450\n",
            "saving 10500\n",
            "saving 10550\n",
            "saving 10600\n",
            "saving 10650\n",
            "saving 10700\n",
            "saving 10750\n",
            "saving 10800\n",
            "saving 10850\n",
            "saving 10900\n",
            "saving 10950\n",
            "saving 11000\n",
            "saving 11050\n",
            "saving 11100\n",
            "saving 11150\n",
            "saving 11200\n",
            "saving 11250\n",
            "saving 11300\n",
            "saving 11350\n",
            "saving 11400\n",
            "saving 11450\n",
            "saving 11500\n",
            "saving 11550\n",
            "saving 11600\n",
            "saving 11650\n",
            "saving 11700\n",
            "saving 11750\n",
            "saving 11800\n",
            "saving 11850\n",
            "saving 11900\n",
            "saving 11950\n",
            "saving 12000\n",
            "saving 12050\n",
            "saving 12100\n",
            "saving 12150\n",
            "saving 12200\n",
            "saving 12250\n",
            "saving 12300\n",
            "saving 12350\n",
            "saving 12400\n",
            "saving 12450\n",
            "saving 12500\n",
            "saving 12550\n",
            "saving 12600\n",
            "saving 12650\n",
            "saving 12700\n",
            "saving 12750\n",
            "saving 12800\n",
            "saving 12850\n",
            "saving 12900\n",
            "saving 12950\n",
            "saving 13000\n",
            "saving 13050\n",
            "saving 13100\n",
            "saving 13150\n",
            "saving 13200\n",
            "saving 13250\n",
            "saving 13300\n",
            "saving 13350\n",
            "saving 13400\n",
            "saving 13450\n",
            "saving 13500\n",
            "saving 13550\n",
            "saving 13600\n",
            "saving 13650\n",
            "saving 13700\n",
            "saving 13750\n",
            "saving 13800\n",
            "saving 13850\n",
            "saving 13900\n",
            "saving 13950\n",
            "saving 14000\n",
            "saving 14050\n",
            "saving 14100\n",
            "saving 14150\n",
            "saving 14200\n",
            "saving 14250\n",
            "saving 14300\n",
            "saving 14350\n",
            "saving 14400\n",
            "saving 14450\n",
            "saving 14500\n",
            "saving 14550\n",
            "saving 14600\n",
            "saving 14650\n",
            "saving 14700\n",
            "saving 14750\n",
            "saving 14800\n",
            "saving 14850\n",
            "saving 14900\n",
            "saving 14950\n",
            "saving 15000\n",
            "saving 15050\n",
            "saving 15100\n",
            "saving 15150\n",
            "saving 15200\n",
            "saving 15250\n",
            "saving 15300\n",
            "saving 15350\n",
            "saving 15400\n",
            "saving 15450\n",
            "saving 15500\n",
            "saving 15550\n",
            "saving 15600\n",
            "saving 15650\n",
            "saving 15700\n",
            "saving 15750\n",
            "saving 15800\n",
            "saving 15850\n",
            "saving 15900\n",
            "saving 15950\n",
            "saving 16000\n",
            "saving 16050\n",
            "saving 16100\n",
            "saving 16150\n",
            "saving 16200\n",
            "saving 16250\n",
            "saving 16300\n",
            "saving 16350\n",
            "saving 16400\n",
            "saving 16450\n",
            "saving 16500\n",
            "saving 16550\n",
            "saving 16600\n",
            "saving 16650\n",
            "saving 16700\n",
            "saving 16750\n",
            "saving 16800\n",
            "saving 16850\n",
            "saving 16900\n",
            "saving 16950\n",
            "saving 17000\n",
            "saving 17050\n",
            "saving 17100\n",
            "saving 17150\n",
            "saving 17200\n",
            "saving 17250\n",
            "saving 17300\n",
            "saving 17350\n",
            "saving 17400\n",
            "saving 17450\n",
            "saving 17500\n",
            "saving 17550\n",
            "saving 17600\n",
            "saving 17650\n",
            "saving 17700\n",
            "saving 17750\n",
            "saving 17800\n",
            "saving 17850\n",
            "saving 17900\n",
            "saving 17950\n",
            "saving 18000\n",
            "saving 18050\n",
            "saving 18100\n",
            "saving 18150\n",
            "saving 18200\n",
            "saving 18250\n",
            "saving 18300\n",
            "saving 18350\n",
            "saving 18400\n",
            "saving 18450\n",
            "saving 18500\n",
            "saving 18550\n",
            "saving 18600\n",
            "saving 18650\n",
            "saving 18700\n",
            "saving 18750\n",
            "saving 18800\n",
            "saving 18850\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ServiceUnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f64c865b874a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtext_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"paragraph\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mquestions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenereer_vragen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'context'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'questions'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-e6018303474d>\u001b[0m in \u001b[0;36mgenereer_vragen\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   completions = openai.Completion.create(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             return (\n\u001b[0;32m--> 620\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    621\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             raise error.ServiceUnavailableError(\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0;34m\"The server is overloaded or not ready yet.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
          ]
        }
      ]
    }
  ]
}